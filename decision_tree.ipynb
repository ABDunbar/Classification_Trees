{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from Packages.data import load_csv_to_dataframe, plot_roc_curve, plot_feature_importance # show_tree,\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, VotingClassifier\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_curve\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from Packages.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
      "       'tenure', 'PhoneService', 'MultipleLines', 'InternetService',\n",
      "       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
      "       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
      "       'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn', 'Churn_cat',\n",
      "       'tenure_cat', 'MonthlyCharges_cat', 'TotalCharges_cat'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "file = '../Data/data.csv'\n",
    "df = load_csv_to_dataframe(file)\n",
    "delete = pd.read_csv(file)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataframe for train, validation, test split\n",
    "\n",
    "* 'customerID': drop. A random string assigned to each customer.\n",
    "* 'tenure'    : drop. A categorical feature was created for this.\n",
    "* 'MonthlyCharges' : drop. A categorical feature was created for this.\n",
    "* 'TotalCharges'   : drop. A categorical feature ...\n",
    "* 'Churn'          : drop. The label is dropped from the X_train, X_test, X_valid datasets\n",
    "\n",
    "The 'X' dataframe is then one hot encoded via pandas.get_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['customerID', 'tenure', 'MonthlyCharges', 'TotalCharges', 'Churn', 'Churn_cat'], axis=1)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "y = df['Churn_cat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training, validation and test\n",
    "\n",
    "The full dataset is split into three parts (training, test, validation).  \n",
    "\n",
    "Stratified splits due to the unequal partitioning of the dataset (No: 5163 (73%), Yes: 1869 (27%))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_valid(X, y):\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_trainval, y_trainval, test_size=0.2,  random_state=42)\n",
    "    return X_train, X_test, X_valid, y_train, y_test, y_valid\n",
    "\n",
    "def train_test(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42) #  \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_valid, y_train, y_test, y_valid = train_test_valid(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe: (7032, 25), X.shape: (7032, 30), y.shape: (7032,)\n",
      "training shape: (4500, 30), validiation shape: (1125, 30), testing shape: (1407, 30)\n",
      "training labels: (4500,), validation shape: (1125,), testing labels: (1407,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataframe: {df.shape}, X.shape: {X.shape}, y.shape: {y.shape}\")\n",
    "print(f\"training shape: {X_train.shape}, validiation shape: {X_valid.shape}, testing shape: {X_test.shape}\")\n",
    "print(f\"training labels: {y_train.shape}, validation shape: {y_valid.shape}, testing labels: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DecisionTreeClassifier Model\n",
    "\n",
    "The assignment is to compare a Decision Tree classifier with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the future....\n",
    "# Best params: {'max_depth': 5, 'max_features': 30, 'max_leaf_nodes': 10, 'min_samples_split': 3}\n",
    "tree_clf = DecisionTreeClassifier(max_depth=5, max_features=30, max_leaf_nodes=10, min_samples_split=3)\n",
    "# tree_clf = DecisionTreeClassifier()\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_predict = tree_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.8578\n",
      "Accuracy on test set:     0.8586\n",
      "Accuracy on validation set: 0.8578\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy on training set: {tree_clf.score(X_train, y_train):.4f}\")\n",
    "print(f\"Accuracy on test set:     {tree_clf.score(X_test, y_test):.4f}\")\n",
    "print(f\"Accuracy on validation set: {tree_clf.score(X_valid, y_valid):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of train / test\n",
    "\n",
    "Accuracy reports how many correct out of total.  This can be misleading if the dataset is very highly skewed.  In this case predictions of only 1 (no churn) will score above 70%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73066667, 0.75133333, 0.72066667])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class NeverChurnClassifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "    \n",
    "never_churn_clf = NeverChurnClassifier()\n",
    "cross_val_score(never_churn_clf, X_train, y_train, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "\n",
    "Cross-Validation predictions based on default DecisionTreeClassifer() (tree_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "poor_clf = DecisionTreeClassifier()\n",
    "poor_clf.fit(X_train, y_train)\n",
    "y_poor_predict = poor_clf.predict(X_test)\n",
    "y_poor_predict_cv = cross_val_predict(poor_clf, X_train, y_train, cv=5)\n",
    "scores = cross_val_score(poor_clf, X_train, y_train, cv=5, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.39838743 0.3958114  0.38729833 0.372678   0.3653514 ]\n",
      "Mean:  0.38390531227789304\n",
      "Std:  0.01290968220896012\n"
     ]
    }
   ],
   "source": [
    "y_predict_cv = cross_val_predict(tree_clf, X_train, y_train, cv=5)\n",
    "scores = cross_val_score(tree_clf, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores: \", scores)\n",
    "    print(\"Mean: \", scores.mean())\n",
    "    print(\"Std: \", scores.std())\n",
    "    \n",
    "display_scores(rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix results for predict and cross-val predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.8578\n",
      "Accuracy on test set:     0.8586\n",
      "Accuracy on cv set:     0.9920\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix results\n",
    "print(f\"Accuracy on training set: {tree_clf.score(X_train, y_train):.4f}\")\n",
    "print(f\"Accuracy on test set:     {tree_clf.score(X_test, y_test):.4f}\")\n",
    "print(f\"Accuracy on cv set:     {tree_clf.score(X_train, y_predict_cv):.4f}\")\n",
    "# print(confusion_matrix(y_test, y_predict))\n",
    "# print(confusion_matrix(y_train, y_predict_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report\n",
    "\n",
    "Classification report for a 'straight' Decision Tree classifier and one for a Cross-Validation (5-fold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_predict))\n",
    "print(classification_report(y_train, y_predict_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Precision, Recall and F1 Scores\n",
    "print(\"Precision, Recall, F1 scores for Churn=yes\")\n",
    "print(\"=\"*42)\n",
    "print(f\"Precision: {precision_score(y_test, y_predict):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_predict):.4f}\")\n",
    "print(f\"F1: {f1_score(y_test, y_predict):.4f}\")\n",
    "print('*'*8 + \"Cross-Validation \"+'*'*8)\n",
    "print(f\"Precision (cv): {precision_score(y_train, y_predict_cv):.4f}\")\n",
    "print(f\"Recall (cv): {recall_score(y_train, y_predict_cv):.4f}\")\n",
    "print(f\"F1 (cv): {f1_score(y_train, y_predict_cv):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute y scores for input to metrics\n",
    "y_probas = cross_val_predict(tree_clf, X_train, y_train, cv=5, method='predict_proba')  # method='decision_function'\n",
    "y_scores = y_probas[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_train, y_scores)\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC\n",
    "\n",
    "The Area Under Curve (AUC) returns ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC AUC Curve\n",
    "print(f\"ROC AUC: {roc_auc_score(y_train, y_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment on ROC and AUC\n",
    "\n",
    "* Score of 0.8831 on Area under the curve => "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Feature importances:\\n{tree_clf.feature_importances_}\")\n",
    "\n",
    "plot_feature_importance(X, tree_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment on Feature Importance\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=5, max_features=30, max_leaf_nodes=10, min_samples_split=3)\n",
    "\n",
    "* The Decision Tree classifier was created with max_features set to 30.  \n",
    "* The model uses ? features (5?). \n",
    "* The first split is at Senior Citizen.  \n",
    "* What is the 'gini' and purity, etc ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set Size on Error Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(model, X, y):\n",
    "    X_train, X_test, X_valid, y_train, y_test, y_valid = train_test_valid(X, y)\n",
    "    train_errors, test_errors, val_errors = [], [], []\n",
    "    for m in range(1, len(X_train)):\n",
    "        model.fit(X_train[:m], y_train[:m])\n",
    "        y_predict = model.predict(X_train[:m])\n",
    "        y_test_predict = model.predict(X_test)\n",
    "        y_valid_predict = model.predict(X_valid)\n",
    "        train_errors.append(mean_squared_error(y_train[:m], y_predict))\n",
    "        test_errors.append(mean_squared_error(y_test, y_test_predict))\n",
    "        val_errors.append(mean_squared_error(y_valid, y_valid_predict))\n",
    "    \n",
    "    plt.plot(np.sqrt(train_errors), \"r-+\", lw=1, label=\"train\")\n",
    "    plt.plot(np.sqrt(test_errors), \"g--\", lw=2, label=\"test\")\n",
    "    plt.plot(np.sqrt(val_errors), \"b-\", lw=2, label='validation')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf = DecisionTreeClassifier(max_depth=5, max_features=30, max_leaf_nodes=10, min_samples_split=3)\n",
    "plot_learning_curves(model_clf, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf = DecisionTreeClassifier()\n",
    "plot_learning_curves(model_clf, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf = DecisionTreeClassifier(max_depth=5, max_features=30, max_leaf_nodes=10, min_samples_split=3)\n",
    "plot_learning_curves(model_clf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search CV : Decision Tree Classifier\n",
    "\n",
    "Consider exploring the following parameters...\n",
    "\n",
    "* 'criterion' : ['gini', 'entropy']\n",
    "* 'max_depth' :\n",
    "* 'min_samples_split' :\n",
    "* 'min_samples_leaf' :\n",
    "* 'max_features' :\n",
    "* 'max_leaf_nodes' :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search CV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'max_depth' : [2, 5, 10, 20],\n",
    "          'min_samples_split': [3, 10, 30],\n",
    "          'max_leaf_nodes': [3, 10, 30],\n",
    "          'max_features': [3, 10, 30]}\n",
    "# \n",
    "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, verbose=1, cv=5)\n",
    "grid_search_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search CV: best score, best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Grid search CV, best estimator: {grid_search_cv.best_estimator_}\")\n",
    "print(f\"Best score: {grid_search_cv.best_params_}\")\n",
    "print(f\"Best params: {grid_search_cv.best_params_}\")\n",
    "print(f\"Best index: {grid_search_cv.best_index_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search CV: best parameters for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best parameters from fit on X_train, y_train\n",
    "best_params = grid_search_cv.best_params_\n",
    "# Instantiate Decision Tree Classifier from those best parameters\n",
    "tree_clf_bp = DecisionTreeClassifier(**best_params)\n",
    "# Fit Classifier on Validation set\n",
    "tree_clf_bp.fit(X_valid, y_valid)\n",
    "# check on test set\n",
    "bp_score = tree_clf_bp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_bp = tree_clf_bp.predict(X_test)\n",
    "#y_predict_bp.shape\n",
    "\n",
    "results = pd.DataFrame(grid_search_cv.cv_results_)\n",
    "print(results.shape)\n",
    "# results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrs = grid_search_cv.cv_results_\n",
    "# for mean_score, params in zip(cvrs['mean_test_score'], cvrs['params']):\n",
    "#     print(np.sqrt(mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of DT, CV and GSCV prediction scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy on training set: {tree_clf.score(X_train, y_train):.4f}\")\n",
    "print(f\"Accuracy on test set: {tree_clf.score(X_test, y_test):.4f}\")\n",
    "print(f\"Accuracy from fit on validation set: {bp_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report Comparison: DT, CV and GSCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=====================  y_test -- y_predict ============\")\n",
    "print(\"=\"*55)\n",
    "print(classification_report(y_test, y_predict))\n",
    "print(\"=\"*55)\n",
    "print(\"============  y_train -- y_predict | Cross-Validation ====\")\n",
    "print(\"=\"*55)\n",
    "print(classification_report(y_train, y_predict_cv))\n",
    "print(\"=\"*55)\n",
    "print(\"===  y_test -- y_predict_best_parameters | using validation set ==\")\n",
    "print(\"=\"*55)\n",
    "print(classification_report(y_test, y_predict_bp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler(feature_range=(0,1))\n",
    "# scaler.fit(X_train)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "# X_valid = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{clf.predict_proba(X_test).shape}\")\n",
    "\n",
    "print(f\"Accuracy score on train data: {clf.score(X_train, y_train):.4f}\")\n",
    "print(f\"Accuracy score on test data: {clf.score(X_test, y_test):.4f}\")\n",
    "print(f\"Accuracy score on validation data: {clf.score(X_valid, y_valid):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('classifier', RandomForestClassifier())])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'classifier' : [LogisticRegression()],\n",
    "        'classifier__penalty' : ['l1', 'l2'],\n",
    "        'classifier__C' : np.logspace(-4, 4, 20),\n",
    "        'classifier__solver' : ['liblinear']\n",
    "    },\n",
    "    {\n",
    "        'classifier' : [RandomForestClassifier()],\n",
    "        'classifier__n_estimators' : list(range(10, 101, 10)),\n",
    "        'classifier__max_features' : list(range(6, 32, 5))\n",
    "    }\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid = param_grid, cv=5, verbose=True, n_jobs=-1)\n",
    "\n",
    "best_clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print ('Max auc_roc:', best_clf.scores_[1].max())\n",
    "\n",
    "print(f\"Accuracy score on train data: {best_clf.score(X_train, y_train):.4f}\")\n",
    "print(f\"Accuracy score on test data: {best_clf.score(X_test, y_test):.4f}\")\n",
    "print(f\"Accuracy score on validation data: {best_clf.score(X_valid, y_valid):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Parameter Settings\n",
    "\n",
    "https://github.com/scikit-learn/scikit-learn/issues/6619"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1 (Lasso) penalty\n",
    "\n",
    "searchCV = LogisticRegressionCV(\n",
    "    # Each of the values in Cs describes the inverse of regularization strength.\n",
    "    Cs=list(np.power(10.0, np.arange(-10, 10))),\n",
    "    # penalty{‘l1’, ‘l2’, ‘elasticnet’}, default=’l2’\n",
    "    # The ‘newton-cg’, ‘sag’ and ‘lbfgs’ solvers support only l2 penalties. \n",
    "    # ‘elasticnet’ is only supported by the ‘saga’ solver.\n",
    "    penalty='l1',\n",
    "    # The default scoring option used is ‘accuracy’.\n",
    "    # For a list of scoring functions that can be used, look at sklearn.metrics\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    random_state=777,\n",
    "    max_iter=10000,\n",
    "    # Specifies if a constant (a.k.a. bias or intercept) should be added to the decision function.\n",
    "    # fit_intercept : bool, default=True\n",
    "    fit_intercept=True,\n",
    "    # Algorithm to use in the optimization problem.\n",
    "    # solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
    "    solver='saga',\n",
    "    # Tolerance for stopping criteria\n",
    "    tol=10\n",
    "    )\n",
    "searchCV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Max auc_roc:', searchCV.scores_[1].max())\n",
    "\n",
    "print(f\"Accuracy score on train data: {searchCV.score(X_train, y_train):.4f}\")\n",
    "print(f\"Accuracy score on test data: {searchCV.score(X_test, y_test):.4f}\")\n",
    "print(f\"Accuracy score on validation data: {searchCV.score(X_valid, y_valid):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l2 (ridge) penalty\n",
    "\n",
    "searchCV = LogisticRegressionCV(\n",
    "    # Each of the values in Cs describes the inverse of regularization strength.\n",
    "    Cs=list(np.power(10.0, np.arange(-10, 10))),\n",
    "    # penalty{‘l1’, ‘l2’, ‘elasticnet’}, default=’l2’\n",
    "    # The ‘newton-cg’, ‘sag’ and ‘lbfgs’ solvers support only l2 penalties. \n",
    "    # ‘elasticnet’ is only supported by the ‘saga’ solver.\n",
    "    penalty='l2', #'l1', # \n",
    "    # The default scoring option used is ‘accuracy’.\n",
    "    # For a list of scoring functions that can be used, look at sklearn.metrics\n",
    "    scoring='roc_auc',# 'accuracy',#'neg_log_loss',#\n",
    "    cv=5,\n",
    "    random_state=777,\n",
    "    max_iter=10000,\n",
    "    # Specifies if a constant (a.k.a. bias or intercept) should be added to the decision function.\n",
    "    # fit_intercept : bool, default=True\n",
    "    fit_intercept=True,\n",
    "    # Algorithm to use in the optimization problem.\n",
    "    # solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
    "    solver='newton-cg',#'lbfgs', # 'sag',#\n",
    "    # l1_ratioslist of float, default=None\n",
    "    #l1_ratios = [0.5],\n",
    "    # Tolerance for stopping criteria\n",
    "    tol=10\n",
    "    )\n",
    "searchCV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(searchCV.scores_)\n",
    "# print(searchCV.coef_)\n",
    "\n",
    "# how to get the final parameters?\n",
    "\n",
    "print ('Max auc_roc:', searchCV.scores_[1].max())\n",
    "\n",
    "print(f\"Accuracy score on train data: {searchCV.score(X_train, y_train):.4f}\")\n",
    "print(f\"Accuracy score on test data: {searchCV.score(X_test, y_test):.4f}\")\n",
    "print(f\"Accuracy score on validation data: {searchCV.score(X_valid, y_valid):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = np.array(results.mean_test_score).reshape(8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(scores, cmap=\"YlGnBu\", vmin=0.75, vmax=1, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Precision - Recall Trade-off (for SGDClassifier)\n",
    "\n",
    "# precisions, recalls, thresholds = precision_recall_curve(y_train, y_scores)\n",
    "#\n",
    "#\n",
    "# def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "#     plt.plot(thresholds, precisions[:,-1], \"b--\", label=\"Precision\")\n",
    "#     plt.plot(thresholds, recalls[:,-1], \"g-\", label=\"Recalls\")\n",
    "#\n",
    "#\n",
    "# plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "\n",
    "\n",
    "\n",
    "# # Confusion Matrix plot\n",
    "# matrix = confusion_matrix(y_test, y_predict)\n",
    "# # create pandas dataframe\n",
    "# class_names = ['Churn_no', 'Churn_yes']\n",
    "# dataframe_Confusion = pd.DataFrame(matrix, index=class_names, columns=class_names)\n",
    "# # create heatmap\n",
    "# sns.heatmap(dataframe_Confusion, annot=True,  cmap=\"Blues\", fmt=\".0f\")\n",
    "# plt.title(\"Confusion Matrix\")\n",
    "# plt.tight_layout()\n",
    "# plt.ylabel(\"True Class\")\n",
    "# plt.xlabel(\"Predicted Class\")\n",
    "# plt.savefig('./Images/confusion_matrix.png')\n",
    "# # plt.show()\n",
    "#\n",
    "# Plot of Decision Tree\n",
    "# feature_cols = X.columns\n",
    "\n",
    "# pydotplus.graphviz.InvocationException: GraphViz's executables not found\n",
    "# works in Linux after sudo apt-get install graphviz\n",
    "# for Win10, might have to edit Environment variable ???\n",
    "# show_tree(tree_clf, feature_cols, './Images/tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of every classifier for comparison\n",
    "knn_clf = KNeighborsClassifier(7)\n",
    "logcv_clf = LogisticRegressionCV(\n",
    "    Cs=list(np.power(10.0, np.arange(-10, 10))),\n",
    "    penalty='l2', \n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    random_state=777,\n",
    "    max_iter=10000,\n",
    "    fit_intercept=True,\n",
    "    solver='newton-cg',\n",
    "    tol=10\n",
    "    )\n",
    "log_clf = LogisticRegression(max_iter=1000)\n",
    "lsvm_clf = SVC(kernel=\"linear\", C=0.025)\n",
    "rbfsvm_clf = SVC(gamma=2, C=1)\n",
    "gaus_clf = GaussianProcessClassifier(1.0 * RBF(1.0))\n",
    "dtree_clf = DecisionTreeClassifier(max_depth=5)\n",
    "rf_clf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=10)\n",
    "mlpnn_clf = MLPClassifier(max_iter=1000)\n",
    "ada_clf = AdaBoostClassifier()\n",
    "gausb_clf = GaussianNB()\n",
    "qda_clf = QuadraticDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('knn', knn_clf),\n",
    "                ('logcv', logcv_clf),\n",
    "                ('log', log_clf),\n",
    "                ('lsvm', lsvm_clf),\n",
    "                #('rbfsvm', rbfsvm_clf),\n",
    "                ('gaus', gaus_clf),\n",
    "                ('dtree', dtree_clf),\n",
    "                ('rf', rf_clf),\n",
    "                #('mlpnn', mlpnn_clf),\n",
    "                ('ada', ada_clf),\n",
    "                #('gausb', gausb_clf),\n",
    "                #('qda', qda_clf)\n",
    "                ],\n",
    "    voting='hard')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in (knn_clf, log_clf, lsvm_clf,  gaus_clf, dtree_clf, rf_clf, ada_clf,  voting_clf): # rbfsvm_clf,gausb_clf, qda_clf,mlpnn_clf, \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    LogisticRegression(max_iter=2000), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ada_clf = AdaBoostClassifier(\n",
    "#     base_estimator=tree_clf, n_estimators=10,\n",
    "#     algorithm=\"SAMME.R\", learning_rate= 1)\n",
    "# # Accuracy: 0.8606965\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    base_estimator=log_clf, n_estimators=10,\n",
    "    algorithm=\"SAMME.R\", learning_rate= 1)\n",
    "# Accuracy: 0.840085\n",
    "\n",
    "# ada_clf = AdaBoostClassifier(\n",
    "#     base_estimator=voting_clf, n_estimators=10,\n",
    "#     algorithm=\"SAMME\", learning_rate= 1)\n",
    "# # Accuracy: 0.8294243070362474\n",
    "\n",
    "# ada_clf = AdaBoostClassifier(\n",
    "#     base_estimator=bag_clf, n_estimators=10,\n",
    "#     algorithm=\"SAMME.R\", learning_rate= 1)v\n",
    "# # Accuracy: 0.8599857853589197\n",
    "\n",
    "model = ada_clf.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions for test dataset\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print accuracy of the model  \n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(f\"Classification Report: {classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# tree_reg1 = DecisionTreeRegressor(max_depth=5)\n",
    "# tree_reg1.fit(X_train, y_train)\n",
    "\n",
    "# y2 = y - tree_reg1.predict(X)\n",
    "# tree_reg2 = DecisionTreeRegressor(max_depth=4)\n",
    "# tree_reg2.fit(X_train, y2)\n",
    "\n",
    "# y3 = y2 - tree_reg2.predict(X)\n",
    "# tree_reg3 = DecisionTreeRegressor(max_depth=2)\n",
    "# tree_reg3.fit(X_train, y3)\n",
    "\n",
    "# y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))\n",
    "\n",
    "# y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
